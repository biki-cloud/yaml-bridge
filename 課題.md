まず、現在の`思想.md`を確認させてください。

[1 tool called]

構想を確認しました。作ってみて感じた**課題と改善案**を共有します。

---

## 現時点での課題

### 1. AIがYAMLを書く際のガイダンス不足

今のスキーマはバリデーション用であって、**AIが何を書くべきか**の指示としては弱い。例えば「このフィールドにはどんな粒度で書くべきか」がスキーマからは読み取れない。

**改善案:** AIへの指示用プロンプトテンプレート、または各フィールドの記載ガイドラインをYAML/MDで用意する

---

### 2. ワークフローの自動化がない

現状は手動で3ステップ実行する必要がある：

```bash
# 毎回これを打つのは面倒
python3 tools/validate.py ...
python3 tools/to_md.py ...
python3 tools/to_mermaid.py ...
```

**改善案:**

- `make` や1つのラッパースクリプトでまとめて実行
- ファイル保存時に自動実行（ファイルウォッチャー）
- CursorのRuleとして組み込み

---

### 3. AIが修正したYAMLの差分確認が難しい

AIがYAMLを更新したとき、**何が変わったか**を人が把握しにくい。

**改善案:**

- YAMLの差分を見やすく表示するツール
- 変更履歴をYAML内に記録する仕組み

---

### 4. 実装との紐付けがない

設計YAMLと実際のコードが別々に存在していて、**設計と実装の乖離**が起きやすい。

**改善案:**

- YAMLにファイルパスや関数名を記載し、実装との対応を明示
- 実装後に「完了」マークをつける仕組み

---

### 5. 双方向性がない

現状は **AI→YAML→人** の一方向。人がMarkdownを見て「ここ違う」と思っても、YAMLに反映する手段が手動しかない。

**改善案:** 人がMarkdown上でコメントや修正指示を書き、それをAIがYAMLに反映するフロー

---

## 良かった点

1. **構造化による認識合わせ** - AIの考えが曖昧なテキストではなく、構造化された形で可視化される
2. **バリデーションによる品質担保** - AIの出力が最低限の品質を満たしているか自動チェックできる
3. **拡張性** - 新しい案件タイプが出てきてもスキーマを追加するだけ
4. **人間に優しい出力** - YAMLを直接読まなくても、整形されたMDと図で理解できる

---

## 次に取り組むとしたら

優先度が高そうなのは：

| 優先度 | 課題                    | 理由                               |
| ------ | ----------------------- | ---------------------------------- |
| 高     | ワークフロー自動化      | 毎回手動実行は現実的でない         |
| 高     | AIへの記載ガイドライン  | スキーマだけでは書き方がわからない |
| 中     | 差分表示                | レビューの効率化                   |
| 中     | Cursor Ruleへの組み込み | AIが自然にこのフローを使えるように |

---

どの課題から取り組みたいですか？または他に気になる点はありますか？
